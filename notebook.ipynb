{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-Tag-Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository implements part of speech (POS) tagging\n",
    "using an HMM model. This file (`notebook.ipynb`) will walk you how to use this repository and how it works.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. <a href=\"#section1\">Reading the data</a>\n",
    "1. <a href=\"#section2\">Tagset</a>\n",
    "1. <a href=\"#section3\">Taggers</a>\n",
    "1. <a href=\"#section4\">Baseline Tagger</a>\n",
    "1. <a href=\"#section5\">Viterbi: HMM Tagger</a>\n",
    "1. <a href=\"#section6\">Baseline Tagger vs Viterbi</a>\n",
    "1. <a href=\"#section7\">Identifying through Audio</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## Reading the data\n",
    "The dataset consists of thousands of sentences with ground-truth POS tags. \n",
    "\n",
    "The provided load_dataset function will read in the data as a nested list with the outer dimension representing each sentence and inner dimensin representing each tagged word. The following cells will help you go through the representation of the data.\n",
    "\n",
    "The provided code converts all words to lowercase. It also adds a START and END tag for each sentence when it loads the sentence. These tags are just for standardization. They will not be considered in accuracy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "train_set = utils.load_dataset('data/brown-training.txt')\n",
    "dev_set = utils.load_dataset('data/brown-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set has 35655 sentences\n",
      "dev set has 9912 sentences\n",
      "The first sentence of training set has 27 words\n",
      "The 10th word of the first sentence in the training set is \"investigation\" with ground-truth tag \"NOUN\"\n"
     ]
    }
   ],
   "source": [
    "print('training set has {} sentences'.format(len(train_set)))\n",
    "print('dev set has {} sentences'.format(len(dev_set)))\n",
    "print('The first sentence of training set has {} words'.format(len(train_set[0])))\n",
    "print('The 10th word of the first sentence in the training set is \"{}\" with ground-truth tag \"{}\"'.format(train_set[0][9][0], train_set[0][9][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an sample sentence from the training set:\n",
      " [('START', 'START'), ('the', 'DET'), ('fulton', 'NOUN'), ('county', 'NOUN'), ('grand', 'ADJ'), ('jury', 'NOUN'), ('said', 'VERB'), ('friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'IN'), (\"atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', 'PUNCT'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", 'PUNCT'), ('that', 'CONJ'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', 'PERIOD'), ('END', 'END')]\n"
     ]
    }
   ],
   "source": [
    "print('Here is an sample sentence from the training set:\\n', train_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "<h2>Tagset</h2>\n",
    "\n",
    "<p>\n",
    "  The following is an example set of 16 part of speech tags.  \n",
    "      This is the tagset used in the provided \n",
    "Brown corpus.\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li> ADJ adjective\n",
    "<li> ADV adverb\n",
    "<li> IN preposition\n",
    "<li> PART particle (e.g. after verb, looks like a preposition)\n",
    "\n",
    "<li> PRON pronoun\n",
    "<li> NUM number\n",
    "<li> CONJ conjunction\n",
    "<li> UH filler, exclamation\n",
    "\n",
    "<li> TO infinitive\n",
    "<li> VERB verb\n",
    "<li> MODAL modal verb\n",
    "<li> DET determiner\n",
    "\n",
    "<li> NOUN noun\n",
    "<li> PERIOD end of sentence punctuation\n",
    "<li> PUNCT  other punctuation\n",
    "<li> X miscellaneous hard-to-classify items\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "<h2>Taggers</h2>\n",
    "\n",
    "There are two main types of tagging functions:\n",
    "\n",
    "<ul>\n",
    "<li> Baseline tagger\n",
    "<li> Viterbi: HMM tagger\n",
    "</ul>\n",
    "\n",
    "The training data is used to train the parameters of the model and the test sets are used to test its accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "<h2>Baseline Tagger</h2>\n",
    "\n",
    "The Baseline tagger considers each word independently, ignoring previous words and tags. For each word w, it counts how many times w occurs with each tag in the training data. When processing the test data, it consistently gives w the tag that was seen most often. For unseen words, it guesses the tag that's seen the most often in training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import algorithm\n",
    "import importlib\n",
    "importlib.reload(algorithm)\n",
    "print(algorithm.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function baseline in module submitted:\n",
      "\n",
      "baseline(train, test)\n",
      "    Implementation for the baseline tagger.\n",
      "    input:  training data (list of sentences, with tags on the words)\n",
      "            test data (list of sentences, no tags on the words, use utils.strip_tags to remove tags from data)\n",
      "    output: list of sentences, each sentence is a list of (word,tag) pairs.\n",
      "            E.g., [[(word1, tag1), (word2, tag2)], [(word3, tag3), (word4, tag4)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(algorithm.baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent: 0.6091 sec\n",
      "accuracy: 0.9387\n",
      "multi-tag accuracy: 0.9019\n",
      "unseen word accuracy: 0.6782\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "importlib.reload(algorithm)\n",
    "train_set = utils.load_dataset('data/brown-training.txt')\n",
    "dev_set = utils.load_dataset('data/brown-test.txt')\n",
    "start_time = time.time()\n",
    "predicted = algorithm.baseline(train_set, utils.strip_tags(dev_set))\n",
    "time_spend = time.time() - start_time\n",
    "accuracy, _, _ = utils.evaluate_accuracies(predicted, dev_set)\n",
    "multi_tag_accuracy, unseen_words_accuracy, = utils.specialword_accuracies(train_set, predicted, dev_set)\n",
    "\n",
    "print(\"time spent: {0:.4f} sec\".format(time_spend))\n",
    "print(\"accuracy: {0:.4f}\".format(accuracy))\n",
    "print(\"multi-tag accuracy: {0:.4f}\".format(multi_tag_accuracy))\n",
    "print(\"unseen word accuracy: {0:.4f}\".format(unseen_words_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='section5'></a>\n",
    "<h2>Viterbi: HMM Tagger</h2>\n",
    "<p>\n",
    "The Viterbi tagger implements the HMM trellis (Viterbi) decoding algoirthm. The probability of each\n",
    "tag depends only on the previous tag, and the probability of each word depends\n",
    "only on the corresponding tag. This model estimates\n",
    "three sets of probabilities:\n",
    "\n",
    "<ul>\n",
    "<li>  Initial probabilities (How often does each tag occur at the start of\n",
    "a sentence?)\n",
    "<li>  Transition probabilities (How often does tag \\(t_b\\)  follow tag\n",
    "\\(t_a\\)?)\n",
    "<li>  Emission probabilities (How often does tag t yield word w?)\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "All sentences must start with a START token, whose tag is START and must end with an END token, whose tag is END.\n",
    "\n",
    "<p>\n",
    "The algorithm is divided in five main steps:\n",
    "\n",
    "<ul>\n",
    "<li> Count occurrences of tags, tag pairs, tag/word pairs.\n",
    "<li> Compute smoothed probabilities\n",
    "<li> Take the log of each probability\n",
    "<li> Construct the trellis.   Notice that\n",
    "for each tag/time pair, you must store not only\n",
    "the probability of the best path but also a pointer to the\n",
    "previous tag/time pair in that path.\n",
    "<li> Return the best path through the trellis.\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Laplace smoothing is used to get a better performance, since transition and emission probabilities\n",
    "may return zero.\n",
    "Make sure that your code for computing transition and emission probabilities\n",
    "never returns zero.\n",
    "\n",
    "<p>\n",
    "It is expected that Viterbi will perform slightly worse than the baseline\n",
    "code for the Brown development dataset for unseen words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function viterbi in module submitted:\n",
      "\n",
      "viterbi(train, test)\n",
      "    Implementation for the viterbi tagger.\n",
      "    input:  training data (list of sentences, with tags on the words)\n",
      "            test data (list of sentences, no tags on the words)\n",
      "    output: list of sentences with tags on the words\n",
      "            E.g., [[(word1, tag1), (word2, tag2)], [(word3, tag3), (word4, tag4)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(algorithm.viterbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## Comparing accuracy of Baseline Tagger vs Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the accuracy of both functions here. Remember to change the `train_set` and `dev_set` to your desired datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9912\n",
      "['START', 'appointment', 'of', 'william', 's.', 'pfaff', 'jr.', ',', '41', ',', 'as', 'promotion', 'manager', 'of', 'the', 'times-picayune', 'publishing', 'company', 'was', 'announced', 'saturday', 'by', 'john', 'f.', 'tims', ',', 'president', 'of', 'the', 'company', '.', 'END']\n",
      "32\n",
      "stats for viterbi:\n",
      "time spent: 17.6231 sec\n",
      "accuracy: 0.9388\n",
      "multi-tag accuracy: 0.9387\n",
      "unseen word accuracy: 0.2563 \n",
      "\n",
      "stats for baseline:\n",
      "time spent: 18.8243 sec\n",
      "accuracy: 0.9387\n",
      "multi-tag accuracy: 0.9019\n",
      "unseen word accuracy: 0.6782\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "importlib.reload(algorithm)\n",
    "train_set = utils.load_dataset('data/brown-training.txt')\n",
    "dev_set = utils.load_dataset('data/brown-test.txt')\n",
    "start_time = time.time()\n",
    "print(len(utils.strip_tags(dev_set)))\n",
    "print(utils.strip_tags(dev_set)[0])\n",
    "print(len(utils.strip_tags(dev_set)[0]))\n",
    "\n",
    "predicted = algorithm.viterbi(train_set, utils.strip_tags(dev_set))\n",
    "time_spend = time.time() - start_time\n",
    "accuracy, _, _ = utils.evaluate_accuracies(predicted, dev_set)\n",
    "multi_tag_accuracy, unseen_words_accuracy, = utils.specialword_accuracies(train_set, predicted, dev_set)\n",
    "\n",
    "print(\"stats for viterbi:\")\n",
    "print(\"time spent: {0:.4f} sec\".format(time_spend))\n",
    "print(\"accuracy: {0:.4f}\".format(accuracy))\n",
    "print(\"multi-tag accuracy: {0:.4f}\".format(multi_tag_accuracy))\n",
    "print(\"unseen word accuracy: {0:.4f} \\n\".format(unseen_words_accuracy))\n",
    "\n",
    "predicted = algorithm.baseline(train_set, utils.strip_tags(dev_set))\n",
    "time_spend = time.time() - start_time\n",
    "accuracy, _, _ = utils.evaluate_accuracies(predicted, dev_set)\n",
    "multi_tag_accuracy, unseen_words_accuracy, = utils.specialword_accuracies(train_set, predicted, dev_set)\n",
    "\n",
    "print(\"stats for baseline:\")\n",
    "print(\"time spent: {0:.4f} sec\".format(time_spend))\n",
    "print(\"accuracy: {0:.4f}\".format(accuracy))\n",
    "print(\"multi-tag accuracy: {0:.4f}\".format(multi_tag_accuracy))\n",
    "print(\"unseen word accuracy: {0:.4f}\".format(unseen_words_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>\n",
    "## Identifying through Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us if we can identify the speech-tag of words verbally using `speech.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grade'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
